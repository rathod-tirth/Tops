## 2) What is Normalization?

- Normalization is a database design process that aims to reduce data redundancy and improve data integrity by organizing a relational database in a specific way.

- The primary goal of normalization is to eliminate or minimize data anomalies, such as update anomalies, insertion anomalies, and deletion anomalies, that can occur when data is not properly structured.

- Normalization involves breaking down a large table into smaller, related tables and defining relationships between them. The process is guided by a set of rules or normal forms.

Here's a brief overview of the most commonly used normal forms:

1. **First Normal Form (1NF):** In 1NF, a table is considered normalized when it has no repeating groups or arrays, and each column contains atomic (indivisible) values. It ensures that each cell in the table contains a single, indivisible piece of data.

2. **Second Normal Form (2NF):** A table is in 2NF when it is in 1NF and all non-key attributes (attributes that are not part of the primary key) are fully functionally dependent on the entire primary key. This means that there are no partial dependencies on a composite primary key.

3. **Third Normal Form (3NF):** A table is in 3NF when it is in 2NF and has no transitive dependencies. This means that attributes not part of the primary key should not depend on other non-key attributes. Transitive dependencies are eliminated by creating separate tables for related data.

4. **Boyce-Codd Normal Form (BCNF):** BCNF is a stricter form of normalization than 3NF. In BCNF, for every non-trivial functional dependency, the left-hand side of the dependency must be a superkey. This ensures that there are no redundancy or anomalies related to candidate keys.
